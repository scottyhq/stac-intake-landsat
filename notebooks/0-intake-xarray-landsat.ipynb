{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use intake + STAC to facilitate loading landsat8 data into xarray\n",
    "\n",
    "#### STAC 0.6 has a lot of improvements over 0.5, so let's try to use that. \n",
    "\n",
    "#### STAC 0.6 search api is not quite finished (for dynamic catalog generation)! so for now, just use static catalog\n",
    "    \n",
    "    * https://github.com/radiantearth/stac-spec \n",
    "    * https://github.com/sat-utils/sat-api \n",
    "\n",
    "DevelopmentSeed has put together a complete STAC catalog for landsat on AWS:\n",
    "\n",
    "    * https://github.com/sat-utils/sat-stac-landsat \n",
    "\n",
    "The catalog is essentially a bunch of nested JSON files starting here:\n",
    "\n",
    "    * https://landsat-stac.s3.amazonaws.com/catalog.json\n",
    "\n",
    "You can traverse the 'child' links to get to a specific image, for example:\n",
    "collection level metadata here:\n",
    "\n",
    "    * https://landsat-stac.s3.amazonaws.com/landsat-8-l1/catalog.json\n",
    "\n",
    "Listing of all images for a particular path/row:\n",
    "\n",
    "    * https://landsat-stac.s3.amazonaws.com/landsat-8-l1/047/027/catalog.json\n",
    "\n",
    "Metadata for a single image (\"STAC item\"):\n",
    "\n",
    "    * https://landsat-stac.s3.amazonaws.com/landsat-8-l1/047/027/2018-01-13/LC80470272018013LGN00.json\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import intake\n",
    "import hvplot.xarray\n",
    "import requests\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import os\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get file paths from STAC \n",
    "* consider adding this functionality to a new intake-stac plugin? might want to incoporate these \n",
    "* STAC is geojson, so can convert directly to python dictionary and therefore pandas dataframe\n",
    "* for satellite imagery stac items, they have polygon footprints with varying amounts of metadata, so well suited to a geopandas geodataframe\n",
    "    * items can have many imagery assets (multiband images) having different resolutions. xarray best suited to loading images with same resolution and footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta(stac_item):\n",
    "    ''' turn STAC item into python dictionary'''\n",
    "    #print(f'retrieving metadata for {stac_item}')\n",
    "    stac_item = stac_item\n",
    "    response = requests.get(stac_item)\n",
    "    meta = response.json() #all metadata, could sort for tier1 here, best to use sat-api/sat-search\n",
    "    return meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(stac_item):\n",
    "    ''' dataframe of asset links from stac item'''\n",
    "    response = requests.get(stac_item)\n",
    "    meta = response.json()\n",
    "    df = pd.DataFrame.from_dict(meta['assets'],orient='index')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(stac_catalog):\n",
    "    ''' turn STAC catalog containing items into pandas dictionary '''\n",
    "    dictionary = {} \n",
    "    response = requests.get(stac_catalog)\n",
    "    inventory = response.json()\n",
    "    items = [x['href'] for x in inventory['links'] if 'item' in x.values()]\n",
    "    for i in items:\n",
    "        url = os.path.join(os.path.dirname(stac_catalog),i)\n",
    "        #print(url)\n",
    "        meta = get_meta(url)\n",
    "        #meta['properties']['index'] = meta['assets']['index']['href']\n",
    "        meta['properties']['stac'] = url\n",
    "        \n",
    "        date = pd.to_datetime(meta['properties']['datetime'])\n",
    "        dictionary[date] = meta['properties']\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(dictionary, orient='index')\n",
    "    df['datetime'] = pd.to_datetime(df.datetime.str[:10]) #for convenience later...\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow because using network to get geojson for each STAC item...\n",
    "# could read info in parallel / avoid for loop?\n",
    "baseurl = 'https://landsat-stac.s3.amazonaws.com/landsat-8-l1'\n",
    "path = 47\n",
    "row = 27\n",
    "stac_subcat = f'{baseurl}/{path:03d}/{row:03d}/catalog.json'\n",
    "\n",
    "DF = create_dataframe(stac_subcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(DF), 'STAC items in catalog:' ) \n",
    "DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['landsat:tier'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only T1 data\n",
    "df = DF[DF['landsat:tier'] == 'T1'].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df), 'STAC items selected:' )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.stac.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_links(df.stac.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Item: All 30m bands from specific scene with intake catalog\n",
    "\n",
    "* intake is helpful for putting the logic to load STAC items into an xarray DataArray behind the scenes\n",
    "* would be nice to allow loading into a dataset instead of dataarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspired by: https://www.anaconda.com/blog/developer-blog/intake-parsing-data-from-filenames-and-paths/\n",
    "# NOTE: incorrect dimensions / chunksize\n",
    "# NOTE: bands have different resolutions / dimensions: https://www.usgs.gov/media/images/landsat-8-band-designations\n",
    "cat = intake.Catalog('intake-landsat-30m.yml')\n",
    "ds = cat.aws_landsat_8().to_dask()\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slow... pulls 9 probably pulling 9 images to local memory? - would be better to pull high resolution overviews first for speed?\n",
    "# Could create another intake source for just RGB thumbnails and display those...\n",
    "#cat.aws_landsat_8.plot.band_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple items: Load all Tier1 data from specific row and column into an xarray Dataset\n",
    "\n",
    "* need some new functionality in intake-xarray to do this \n",
    "* code below is made in hase, probable not very efficient\n",
    "* first, browse all the pre-made RGB thumbnail images\n",
    "* seems to be a lot happening with boto getting AWS credentials for every image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First... a thumbnail browser! NOTE: these thumbnail JPGs are not georeferenced... but RGB COG\n",
    "# would be neat b/c we'd have coordinates and resolution updated w/ datashader\n",
    "images = []\n",
    "for i,row in df.iterrows():\n",
    "    #print(row.datetime)\n",
    "    da = cat.aws_landsat_8_thumbnails(path=int(row['eo:column']), \n",
    "                                     row=int(row['eo:row']), \n",
    "                                     product_id=row['landsat:product_id']).read()\n",
    "    da = da.expand_dims('time')\n",
    "    da = da.assign_coords(time=[row.datetime])\n",
    "    images.append(da)\n",
    "\n",
    "ds = xr.concat(images, 'time').to_dataset(name='z')\n",
    "\n",
    "# NOTE: hvplot rgb only seems to work if 'band coordinate comes first!\n",
    "coords = dict(band=(['band'], ds.coords['band'].values),\n",
    "              time=(['time'], ds.coords['time'].values),\n",
    "              y=(['y'], ds.coords['y'].values),\n",
    "              x=(['x'], ds.coords['x'].values),\n",
    "              )\n",
    "\n",
    "ds = xr.Dataset({'z': (['time','band','y','x'], ds['z'].data.astype('uint8'))}, coords=coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.hvplot.rgb('x','y', z='z',bands='band',groupby='time', width=700, height=500).options(invert_yaxis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(stac_catalog, template='intake-landsat-30m.yml'):\n",
    "    ''' create an xarray.DataSet from tier1 data in landsat STAC catalog'''\n",
    "    datasets = []\n",
    "    # NOTE: slow b/c reading over network\n",
    "    DF = create_dataframe(stac_catalog) #NOTE: alternatively use devseed sat-search first to filter larger catalog...\n",
    "    df = DF[DF['landsat:tier'] == 'T1'].sort_index()\n",
    "    df.index.name = 'time'\n",
    "    \n",
    "    cat = intake.Catalog('intake-landsat-30m.yml')\n",
    "    #slow\n",
    "    for i,row in df.iterrows():\n",
    "        print(row.datetime)\n",
    "        da = cat.aws_landsat_8(path=int(row['eo:column']), row=int(row['eo:row']), product_id=row['landsat:product_id']).to_dask()\n",
    "        ds = da.to_dataset(dim='band')\n",
    "        datasets.append(ds)\n",
    "    \n",
    "    DS = xr.concat(datasets, dim=df.index)\n",
    "    \n",
    "    return DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: try rasterio context manager to avoid trying to get aws credentials w/ boto?\n",
    "# How to speed this up?\n",
    "stac_catalog = 'https://landsat-stac.s3.amazonaws.com/landsat-8-l1/047/027/catalog.json'\n",
    "DS = create_dataset(stac_catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NDVI calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rechunk since chunk sizes is adjusted when loading scenes w/ different dimensions and do an NDVI calculation\n",
    "ds = DS.chunk(dict(time=1, x=DS.dims['x'], y=512))\n",
    "NDVI = (ds[5] - ds[4]) / (ds[5] + ds[4])\n",
    "NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and visualize! - best to use dask for this...\n",
    "#img = NDVI.hvplot('x', 'y', groupby='time', dynamic=True, rasterize=True, width=700, height=500, cmap='magma')\n",
    "#img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What if we want to work with images not in the same Path and Row?\n",
    "\n",
    "### The answer is more difficult than you might expect!\n",
    "\n",
    "* Landsat scenes are referenced on a global path/row grid system and overlap.\n",
    "* Scenes are stored in different projected coordinate reference systems (UTM zones)\n",
    "* because of the 'swath' nature of satellite imagery, we end up having to store a lot of nan values in our xarray dataset (maybe sparse arrays can help here?)\n",
    "    * Eventually we want some intelligent way to access \"mosaiic\" and \"composite\" images (https://developers.google.com/earth-engine/ic_composite_mosaic)\n",
    "\n",
    "\n",
    "Here is a simple example for a particulare date 2013-07-26 from path=47, row=27 and scene to south (row=28)\n",
    "* I end up defering to GDAL, but could use rasterio python library to avoid external function calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "north = df[df['datetime'] == \"2013-07-26\"].stac.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_north = get_links(north)['href']['B1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_l8item(stac_catalog, date):\n",
    "    ''' only for landsat'''\n",
    "    response = requests.get(stac_catalog)\n",
    "    data = response.json()\n",
    "    items = [x['href'] for x in data['links'] if 'item' in x.values()]\n",
    "    item = [x for x in items if date in x]\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2013-07-26'\n",
    "stac_catalog = 'https://landsat-stac.s3.amazonaws.com/landsat-8-l1/047/028/catalog.json'\n",
    "get_l8item(stac_catalog, date)\n",
    "# NOTE: two returned b/c tier1, tier2, etc\n",
    "\n",
    "south = stac_catalog.replace('catalog.json','2013-07-26/LC80470282013207LGN01.json')\n",
    "img_south = get_links(south)['href']['B1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a VRT that merges these adjacent, slightly overlapping scenes\n",
    "# https://www.gdal.org/gdalbuildvrt.html\n",
    "# pixels from last file in list are used for overlaps\n",
    "#cmd = f'gdal_merge.py -of VRT -n 0 -o merged.vrt /vsicurl/{img_north} /vsicurl/{img_south}' #won't write to vrt\n",
    "cmd = f'gdalbuildvrt -overwrite -vrtnodata 0 -srcnodata 0 merged.vrt /vsicurl/{img_north} /vsicurl/{img_south}'\n",
    "\n",
    "print(cmd)\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open this file with xarray\n",
    "da = xr.open_rasterio('merged.vrt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = da.hvplot.image(rasterize=True, dynamic=True, datashade=True, width=700, height=500, cmap='magma')\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How about all of washington state?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_sat_api(data, stac_version=0.5):\n",
    "    '''https://github.com/sat-utils/sat-api'''\n",
    "    \n",
    "    if stac_version == 0.5:\n",
    "        baseurl = 'https://sat-api.developmentseed.org/search/stac' #0.5\n",
    "    elif stac_version == 0.6:\n",
    "        baseurl = 'https://sat-api-dev.developmentseed.org/stac/search' #0.6\n",
    "\n",
    "    r = requests.get(baseurl, params=data, timeout=100)\n",
    "    #print(r.url)\n",
    "    # Save Directly to dataframe\n",
    "    # df = pd.DataFrame(r.json()[0])\n",
    "    print('Saved results to response.json')\n",
    "    with open('response.json', 'w') as j:\n",
    "        j.write(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to simplify multipolygon (w/ islands)\n",
    "#with open('washington.json') as f:\n",
    "#    aoi = f.read()\n",
    "\n",
    "with open('wa-bbox.geojson') as f:\n",
    "    aoi = f.read()\n",
    "\n",
    "    \n",
    "#All WA state in 2017\n",
    "stac5 = {'c:id':'landsat-8-l1',\n",
    "        'intersects':aoi,\n",
    "        'datetime':'2017-07-01/2017-08-01',\n",
    "        #'eo:cloud_cover':'0/50',\n",
    "        'limit':1000}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_sat_api(stac5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load geojson w/ geopandas\n",
    "import geopandas as gpd\n",
    "gf = gpd.read_file('response.json')\n",
    "gf = gf.sort_values('datetime')\n",
    "print('records:', len(gf))\n",
    "gf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter tier 1 scenes\n",
    "gf = gf[gf.id.str.endswith('T1')]\n",
    "gf['datetime'] = pd.to_datetime(gf.datetime)\n",
    "gf['date'] = gf.datetime.apply(lambda x: x.date())\n",
    "print('tier1 scenes:', len(gf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: landsat8 has a 16 day revisit time. So let's plot before the 18th and \n",
    "# after the 18th, should also make sure sorted by acquisition time!\n",
    "thresh = pd.Timestamp('2017-07-17')\n",
    "gf1 = gf[gf.datetime <= thresh]\n",
    "gf2 = gf[gf.datetime > thresh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2) = plt.subplots(1,2, figsize=(8,4))\n",
    "gf1.plot(column='date', edgecolor='k', cmap='magma', alpha=0.5, legend=True, ax=ax1)\n",
    "gf2.plot(column='date', edgecolor='k', cmap='magma', alpha=0.5, legend=True, ax=ax2)\n",
    "leg = ax1.get_legend()\n",
    "leg.set_bbox_to_anchor((0.5, -0.5, 0.2, 0.2))\n",
    "leg = ax2.get_legend()\n",
    "leg.set_bbox_to_anchor((0.5, -0.5, 0.2, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudocode (this is where we want to get to)\n",
    "\n",
    "''' \n",
    "cat = intake.Catalog('intake-landsat-stac.yml')\n",
    "\n",
    "stac_params = {'c:id':'landsat-8-l1',\n",
    "          'intersects':aoi,\n",
    "          'datetime':'2017-07/2017-08'}\n",
    "\n",
    "# select specific bands, resolution, coordinate system, resampling algorithm??\n",
    "#gdal_params = {bands=[4,5],\n",
    "#               res=10}\n",
    "\n",
    "ds = cat.landsat_mosaic(**stac_params).to_dask()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sat_api_item(pid, stac_version=0.5, band='B1'):\n",
    "    '''https://github.com/sat-utils/sat-api'''\n",
    "    \n",
    "    data = {'c:id':'landsat-8-l1',\n",
    "    'id':pid}\n",
    "    \n",
    "    if stac_version == 0.5:\n",
    "        baseurl = 'https://sat-api.developmentseed.org/search/stac' #0.5\n",
    "    elif stac_version == 0.6:\n",
    "        baseurl = 'https://sat-api-dev.developmentseed.org/stac/search' #0.6\n",
    "\n",
    "    r = requests.get(baseurl, params=data, timeout=100)\n",
    "    #return r.json() returns a python dictionary\n",
    "    item = r.json()\n",
    "    \n",
    "    url = item['features'][0]['assets'][band]['href']\n",
    "    return url\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sat_api_item('LC08_L1TP_042027_20170702_20170715_01_T1', stac_version=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get links to all files that will be mosaiced\n",
    "series = gf1.id.apply(get_sat_api_item) #slow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series.to_csv('my_list.txt', index=False, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since frames span multiple UTM zones, need to put into common CRS (WGS84 lat/lon)\n",
    "def utm2latlon(url):\n",
    "    outvrt = os.path.basename(url).replace('TIF','vrt')\n",
    "    cmd = f'gdalwarp -dstnodata 0 -t_srs EPSG:4326 -of VRT /vsicurl/{url} {outvrt}'\n",
    "    #print(cmd)\n",
    "    os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = series.apply(utm2latlon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdalbuildvrt -overwrite -vrtnodata 0 -srcnodata 0 mosaic.vrt LC08*.vrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open this file with xarray\n",
    "da = xr.open_rasterio('mosaic.vrt', chunks=dict(band=1, y=2048, x=2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IT WORKS!.... but....\n",
    "\n",
    "# Taking way too long, not sure how much data is being pulled in the background\n",
    "\n",
    "# See:\n",
    "# https://github.com/pyviz/geoviews/issues/230#issuecomment-435379550\n",
    "\n",
    "img = da.hvplot.image(rasterize=True, dynamic=True, datashade=True, width=700, height=500, cmap='magma')\n",
    "img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
